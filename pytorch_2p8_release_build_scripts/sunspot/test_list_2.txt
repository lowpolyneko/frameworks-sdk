# Python dependency packages for PyTorch-2.8.0 and IPEX-2.8.10 
# and TorchVision-0.23.0
# Removed cmake as we want to depend on system-wide installation
astunparse
expecttest>=0.3.0
filelock
fsspec
hypothesis
jinja2
lintrunner ; platform_machine != "s390x"
networkx
ninja
## This is a special requirement, as I built my PyTorch wheel with numpy==2.0.2
numpy==2.0.2
optree>=0.13.0
packaging
psutil
pytest
pyyaml
requests
ruamel.yaml==0.18.6
scipy>=1.8.0
## PyTorch wants setuptools<=75.8.2
## IPEX wants setuptools==72.1.0
## pytorch-triton-xpu wants setuptools>=70.2.0
setuptools==72.1.0
sympy>=1.13.3
types-dataclasses
typing_extensions
## PyTorch wants a specific version of typing-extensions, IPEX has no restrictions
typing-extensions>=4.10.0
## TorchVision specific requirement
pillow>=5.3.0,!=8.3.*
## pytroch-triton-xpu requires this, for vLLM we need to install it separately
pybind11>=2.13.1
## h5py specific dependency
cython==3.0.11
pkgconfig==1.5.5
## torchdata specific requirements, the < 2.0.0 is future proofing for the 
## torchtune dev setup
urllib3 >= 1.25, < 2.0.0
## torchao specific requirements 
## (These we are asking pip to resolve the dependency for us, we well have a 
## list of manifests with this one)
## They are mentioned in torchao_0.12.0_xpu_separate_requirements.txt
## That should be installed after this file and all torch-ecosystem built
## Otherwise a whole bunch of Nvidia-CUDA stuff comes in!!
## torchao specific requirements
## (These we are asking pip to resolve the dependency for us, we well have a
## list of manifests with this one)
unittest-xml-reporting
parameterized
transformers
sentencepiece
bitsandbytes
matplotlib
pandas
fire
tabulate
tiktoken
blobfile
lm_eval
diskcache
pycocotools
tqdm
importlib_metadata
ruff==0.11.6 ## This was fixed in the repository git hub
pre-commit
## These are torchtune-0.6.1 specific requirements, comes from the
## https://github.com/pytorch/torchtune/blob/v0.6.1/pyproject.toml, and then
## parsed against the torchao_0.12.0 separate requirements file and the
## h5py_3.14.0 main requirements file
#datasets ## This could be redundant, 3.6.0 brought in by torchao
huggingface_hub[hf_transfer]
safetensors
kagglehub
#tokenizers ## This could be redundant, 0.21.4 brought in by torchao
omegaconf
comet_ml>=3.44.2
mlflow
pytest-cov
pytest-mock
pytest-integration
tensorboard
wandb
## vllm_0.10.1 specific requirements
regex
cachetools
blake3
py-cpuinfo
fastapi[standard] >= 0.115.0
aiohttp
openai >= 1.99.1
pydantic >= 2.10
prometheus_client >= 0.18.0
prometheus-fastapi-instrumentator >= 7.0.0
lm-format-enforcer >= 0.10.11, < 0.11
llguidance >= 0.7.11, < 0.8.0; platform_machine == "x86_64" or platform_machine == "arm64" or platform_machine == "aarch64"
outlines_core == 0.2.10
lark == 1.2.2
xgrammar == 0.1.21; platform_machine == "x86_64" or platform_machine == "aarch64" or platform_machine == "arm64"
partial-json-parser
pyzmq >= 25.0.0
msgspec
gguf >= 0.13.0
mistral_common[image,audio] >= 1.8.2
opencv-python-headless >= 4.11.0
six>=1.16.0; python_version > '3.11'
einops
compressed-tensors == 0.10.2
depyf==0.19.0
cloudpickle
watchfiles
python-json-logger
pybase64
cbor2
setproctitle
openai-harmony >= 0.0.3
ray>=2.9
#cmake>=3.26.1
setuptools-scm>=8
wheel
#datasets ## comes in through torchao/torchtune interlinked dependency
numba == 0.60.0
## Squeezing in the two torchtitan dependencies
tomli-w >= 1.1.0
tyro
